{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biases, imbalance and pre-processing\n",
    "\n",
    "Today we will be looking at how to address biases arising from our dataset due to class imbalance, as well as how to get the most out of the data we have with preprocessing.\n",
    "\n",
    "## Categories of machine learning\n",
    "\n",
    "Machine learning can very broadly be divided into four categories: data handling, model design, optimisers, loss selection. In the last session we looked a little bit at model selection, where the capacity/size of the network we were training was an important parameter for reducing overfitting. Model design can also involve choosing different kinds of layers with some kind of inductive bias, but more on this in later sessions. This week we are going to include data handling and loss selection in the exercises.\n",
    "\n",
    "When training models with machine learning data handling is often more important than the choice of model. \n",
    "It is very easy for a model to focus on the \"wrong\" features while training and end up with a strong bias, or latch onto an easy solution that ignores a lot of information. Even worse, models can fail at their task because it is easier to guess and get the right answer than to learn how to solve the task they are assigned!\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "In the previous exercises you were provided with data which had been \"pre-processed\" to make it easier for the network to perform well. \n",
    "\n",
    "Ideally, all inputs to a neural network are of order 1, centered around a common value.\n",
    "\n",
    "You can see this as a logical consequence of our dense layers\n",
    "* Our linear layer $y_j = m_j^{\\,\\,i} x_i + c_j$ has the weights $m_j^{\\,\\,i}$ per node $j$ and per input $i$\n",
    "* Our weights are initialised randomly \n",
    "* If our $x_i$ have values which vary drastically, the inputs $x_i$ with the largest values will dominate the outputs $y_j$\n",
    "* Our gradients will be dominated by a subset of the features\n",
    "* We won't learn everything we could and can end up with an underperforming model\n",
    "\n",
    "This issue can be addressed by rescaling the input data such that all of the features are treated equally. \n",
    "Any invertible transformation we apply to our training features will leave the optimal solution to the problem unchanged. The solution in the transformed coordinates can always be converted to a solution in the original scale by applying the inverse transformation.\n",
    "Rescaling the data such that the input features are more suitable for use with a machine learning algorithm is referred to as preprocessing.\n",
    "Depending on the task and your input data type there are a few standard ways to preprocess the data.\n",
    "\n",
    "For images:\n",
    "* Our inputs are pixels with values from 0-255\n",
    "* We can divide by 255 and ensure our values are between 0 and 1.\n",
    "* If we are dealing with very dark or very light images, we may add an additional scaling\n",
    "\n",
    "For distributions:\n",
    "* We could scale it to be minimum value = 0, maximum value = 1\n",
    "* We scale using the mean and standard deviation of each feature (dimension)\n",
    "  * Subtract the mean from all data per feature, and divide by its standard deviation\n",
    "* We can apply some non-linear scaling (e.g. log) to change the areas of focus\n",
    "  * It really depends on your physics problem! Does the behaviour change linearly, logarithmically, do you have long tails, spikes?\n",
    "\n",
    "There is no set in stone best way to preprocess data for all problems. Smart preprocessing can bring you more performance improvements than a brute force bigger network!\n",
    "\n",
    "### Example\n",
    "\n",
    "Lets load data similar to what you used last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = load_data('data/btag_b_c.h5')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just looking at the preview of the dataset we can see there are a lot of different values and ranges across rows and columns!\n",
    "\n",
    "Let's now look at a few of the individual distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _ = plt.subplots(3, 3, figsize=(14,14))\n",
    "axes = fig.axes\n",
    "variables = ['pt','eta','SV1_L3d',\n",
    "            'IP3D_pu', 'IP3D_pc','IP3D_pb',\n",
    "            'SV1_masssvx', 'SV1_efracsvx', 'SV1_significance3d']\n",
    "\n",
    "class_0 = df.loc[df['label'] == 0] # These are our c-jets\n",
    "class_1 = df.loc[df['label'] == 1] # These are our b-jets\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.hist(class_0[variables[i]], bins=20, label='c-jets', histtype='step')\n",
    "    ax.hist(class_1[variables[i]], bins=20, label='b-jets', histtype='step')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(variables[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the ranges are widely different, and some of these distributions suffer from having very long tails.\n",
    "\n",
    "`IP3D_pu/c/b` for example have most values at 0 but with tails up to 1.0.\n",
    "\n",
    "`pt` has a lot of events with low values but a tail that goes as high as $10^6$!\n",
    "\n",
    "Let's take a look at their mean and standard deviation.\n",
    "\n",
    "As we have loaded our data with pandas dataframes we can take advantage of a lot of nice features from there to do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[variables].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[variables].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('label')[variables].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('label')[variables].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also have noticed that the number of events in each class is very different! This will also be a huge problem when training a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = df['label'].sum() / df.shape[0]\n",
    "print(f'{frac * 100:.2f}% of our events are of class 1.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remember, when taking a wild guess with binary cross entropy we expect the loss to be ln(2).\n",
    "Let's see what happens if we were to guess 0.5 for all of our events in this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_crossentropy(true,pred):\n",
    "    return -(true*np.log(pred+1e-16)+(1-true)*np.log((1-pred)+1e-16)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "guess = 0.5*np.ones_like(df.label.values,dtype=np.float32)\n",
    "print(binary_crossentropy(df.label.values,guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we get our random guess value of ln(2) by randomly guessing on our dataset, and this is us without having learned anything.\n",
    "\n",
    "But what if we just guess another value, without learning anything from our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_range = np.arange(0.05,1.,0.001)\n",
    "bces = [binary_crossentropy(df.label.values,i) for i in plt_range]\n",
    "plt.plot(plt_range,bces,label='Fixed guess')\n",
    "plt.plot(plt_range, 0.69 * np.ones_like(bces),label='Random guess')\n",
    "plt.xlabel('Fixed guess')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we can minimise our loss just by optimising our fixed guess!\n",
    "\n",
    "But this isn't machine learning, this is an underlying bias. We don't need anything but the labels to make this prediction! This would then throw away all information in our features!\n",
    "\n",
    "We can zoom in on this prediction, and we find that the minimum BCE value is well below ln(2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(plt_range,bces)\n",
    "plt.xlabel('Fixed guess')\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel('Loss')\n",
    "plt.annotate(f\"min: y={np.min(bces):.3f}\",(0.8,0.2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we aren't careful, our machine learning model will minimise our loss simply by learning the ratio of the class composition.\n",
    "\n",
    "The more dramatic the imbalance, the harder it will be for a network to see anything else!\n",
    "\n",
    "For a classification task these are the two main problems we need to address:\n",
    "* Bias from class imbalance impacting performance\n",
    "* Tails and large input values impacting performance\n",
    "\n",
    "Of course, we don't want to throw away any of our data just to balance the ratio of the classes. Instead you can try to apply weights to the binary cross entropy loss, such that the loss values of each class are balanced.\n",
    "\n",
    "We can build a simple loss by hand that will do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_binary_crossentropy(true,pred,weight0,weight1):\n",
    "    # Here we apply a weight to each term in the loss function, to change it's relative importance\n",
    "    return -(true*np.log(pred+1e-16)*weight1 + (1-true)*np.log((1-pred)+1e-16)*weight0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should derive two weights, one for each class, that will result in the minimum of the blue curve falling at 0.5.\n",
    "\n",
    "Think about the bias we see above, what it is related to, and how you can derive a simple weight using that information.\n",
    "\n",
    "Hints:\n",
    "\n",
    "* You can get the number of events in a dataframe with ```len(df)``` or ```df.shape[0]```\n",
    "* You can get the number of events in each class by looking at the labels\n",
    "* You want your weights to sum to 1/(number of classes) for the balanced loss here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight_0 = \n",
    "#weight_1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_range = np.arange(0.05,1.,0.001)\n",
    "bces = [weighted_binary_crossentropy(df.label.values,i,weight_0, weight_1) for i in plt_range]\n",
    "plt.plot(plt_range,bces,label='Fixed guess')\n",
    "plt.plot(plt_range, 0.69 * np.ones_like(bces),label='Random guess')\n",
    "plt.xlabel('Fixed guess')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you can now see that random guessing is again the optimal solution like this one below:\n",
    "\n",
    "![fixed bias](data/random_solution.png \"Fixed bias\")\n",
    "\n",
    "So we have fixed the problem we had with our class imbalance by carefully choosing our loss. Tensorflow offers an easy way to apply these weights during training, and scikit learn will give you a simple function to calculate the weights. But we will leave the implementation of this during the training up to you.\n",
    "\n",
    "In tensorflow with keras, when using the \"fit\" function you just need to pass them as an option ```class_weight```.\n",
    "\n",
    "Equally, instead of applying weights per class, you can calculate them per sample.\n",
    "\n",
    "Can you think of how to trivially extend your current solution to be a per-sample weight?\n",
    "\n",
    "In tensorflow with keras you can pass an extra set of values in the fit function with ```sample_weight``` and it needs to have the same length as your inputs and outputs.\n",
    "\n",
    "Can you think of benefits of having a sample weight instead of just a class weight?\n",
    "\n",
    "### Exercises\n",
    "\n",
    "Build a classifier to separate the two classes using the variables defined above as `variables`.\n",
    "\n",
    "You will want to make sure you are dealing with numpy arrays (with pandas dataframes you can use `.values()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#You will need to fill in the blanks!\n",
    "#ins = Input(shape=(9,))\n",
    "#h = Dense(...)(ins)\n",
    "#h = Dense(...)(h)\n",
    "#outs = Dense(...)\n",
    "\n",
    "#opt = Adam(lr=learning_rate)\n",
    "\n",
    "# model = Model(ins=ins,outs=outs)\n",
    "# You can also pass class weights here instead of when fitting!\n",
    "# model.compile(optimizer=opt,loss='bce')\n",
    "\n",
    "### it is also possible to add metrics when compiling to keep track of the models performance while training\n",
    "### just add an option `metrics` with a list of what you want, i.e. metrics=['acc','AUC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we train a classifier we will always use a training and validation set (with the latter used to assess its performance). Ideally we will also have a test set which we use after fully optimising our classifier, this will be the final measure of performance for when we apply our to the real data we collect.\n",
    "\n",
    "Remember, never train your classifier with data you will then apply it on. This is also true for the validation set.\n",
    "\n",
    "In these examples, we will focus only on splitting our data into train and validation, with a 50:50 split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the data for training and validation\n",
    "\n",
    "Load your data and make sure it is shuffled. As it is already loaded, lets just shuffle the dataframe.\n",
    "* Depending on your data format, you make have to use different functions\n",
    "* With pandas dataframes we can do this with `df = df.sample(frac=1)`\n",
    "  * You can use df.head() to return the top 5 rows of the dataframe to check this has shuffled the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shuffle the dataframe\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split the data into two sets, training and validation, with input variables and labels in two separate arrays.\n",
    "\n",
    "* Use the variables array we defined earlier to select the variables, and use the label column for the labels.\n",
    "\n",
    "\n",
    "Tip:\n",
    "\n",
    "You can split arrays/tensors/dataframes in python with the slice operator `:`\n",
    "\n",
    "So for example\n",
    "```x_train = x[:len(x)//2]\n",
    "x_val = x[len(x)//2:]```\n",
    "\n",
    "Remember, you will need to use an int for indices, so make sure to take care of odd numbers of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = df[variables].values[:len(df)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train =\n",
    "# x_val = \n",
    "# y_train =\n",
    "# y_val =\n",
    "### And if you are using sample weights\n",
    "### w_train = \n",
    "### w_val = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have your model compiled and your data loaded, train the classifier with `model.fit`!\n",
    "\n",
    "You can pass both the training and validation sets to the classifier.\n",
    "\n",
    "Or if you want to use only the training data, you can pass that with the option `validation_split` to skim off some of the train data for the validation set. This is sometimes useful for quick studies, but it is better to predefine your datasets to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(.....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot the loss and accuracy values from the model you have trained from the history object\n",
    "`history.history['loss']`,`history.history['val_loss']`,`history.history['acc']`,`history.history['val_acc']`. You can see what is available with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very useful to plot the loss development to check that you have not overtrained the model!\n",
    "\n",
    "You can also now perform extra studies on the performance of the model, looking at the ROC curves or efficiencies as a function of other quantities.\n",
    "\n",
    "First get all your predictions for the validation set and then plot the ROC curves using\n",
    "`sklearn.metrics.roc_curve`\n",
    "\n",
    "Tip: you can always check in the sklearn documentation how to use a function, but if you want to do it inline you can use: `help(function_name)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr,tpr,thresh = roc_curve(.....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tpr,fpr,label='mylabel')\n",
    "plt.xlabel('Signal Efficiency')\n",
    "plt.ylabel('Background Efficiency')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like, you can compare this to a training where you don't use the class weights!\n",
    "\n",
    "Plot both ROC curves on the same plot with different labels to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mymodel2 = ....\n",
    "#mymodel2.compile(...)\n",
    "#mymodel2.fit(...)\n",
    "#pred_val_noweight = mymodel2.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fpr_nw,tpr_nw,thresh_nw = roc_curve(....)\n",
    "# plt.plot(tpr,fpr,label='weighted')\n",
    "# plt.plot(tpr_nw,fpr_nw,label='no weights')\n",
    "# plt.xlabel('Signal Efficiency')\n",
    "# plt.ylabel('Background Efficiency')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing input ranges\n",
    "\n",
    "As mentioned earlier, networks prefer it when inputs are scaled and it can help them converge faster or lead to better performance.\n",
    "\n",
    "Now that you have a balanced classifier, let's look at the input variables again.\n",
    "\n",
    "We know how to calculate the mean and standard deviation, so lets apply this to the variables we are interested in.\n",
    "We should calculate this on the training set and apply it to the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_scale = np.mean(x_train,axis=0,keepdims=True)#axis specifies which column to perform over\n",
    "std_scale = np.std(x_train,axis=0,keepdims=True)#keepdims keeps the same number of axes after the operation (remember broadcasting!)\n",
    "x_train_t = (x_train - mu_scale)/std_scale\n",
    "x_val_t = (x_val - mu_scale)/std_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can train a classifier again, but now with these new values for the inputs, and compare it to the previous performance.\n",
    "If you ever want to reset a network to an untrained state in tf.keras, recompile it.\n",
    "\n",
    "It is not guaranteed which preprocessing will be best out of the box when training a network, and comparing many is always worthwhile!\n",
    "\n",
    "[Scikit learn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) has a great number of preprocessing functions available, feel free to try several of them and compare!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing against input variables\n",
    "\n",
    "Sometimes when we train a classifier we want it to separate classes based on some observables but not based on others.\n",
    "\n",
    "In flavour tagging this is the case with the momentum and angle of the jet - these are our first to variables in the network, $p_T$ and $\\eta$!\n",
    "\n",
    "Unfortunately, if we look at these two features they have different distributions, big problem!\n",
    "\n",
    "If we plot the correlation between the output and one of these two variables we will see there is a trend.\n",
    "\n",
    "To combat this, we can treat it just like we did the class bias and derive a weight per sample as a function of these distributions.\n",
    "\n",
    "To make distributions match we can choose one as a reference, and then work out weights to multiple the other one by to get it to match.\n",
    "\n",
    "Simple method:\n",
    "* Let's use histograms!\n",
    "* Make a histogram for each class (nominal and default) with fine binning (as fine as statistics allows us)\n",
    "* Take a ratio of the number of events in each bin between the nominal and target distributions\n",
    "* Use the ratio as our per-bin weight\n",
    "* Assign each event in the nominal class based on its value\n",
    "\n",
    "With this approach in one dimension we can get pretty close, in two dimensions we start getting limited by statistics, and beyond that we need to be much smarter.\n",
    "\n",
    "We can also use downsampling or other pdf based methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the plot and get the values per bin\n",
    "#we are using weights to normalise the histograms to sum to unity in case we want to use the class weights in training\n",
    "x_train_sig = x_train[y_train==1]\n",
    "x_train_bkg = x_train[y_train==0]\n",
    "bkg_vals,ptbins,_= plt.hist(x_train_bkg[:,0], weights=np.ones(len(x_train_bkg))/len(x_train_bkg), bins=np.arange(0,500e3,10e3),histtype='step',linewidth=2, label='c-jets')\n",
    "signal_vals,ptbins,_=plt.hist(x_train_sig[:,0], weights=np.ones(len(x_train_sig))/len(x_train_sig), bins=np.arange(0,500e3,10e3),histtype='step',linewidth=2, label='b-jets')\n",
    "plt.xlabel('$p_T$ [MeV]')\n",
    "plt.ylabel('Normalised Entries')\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal_vals = weights * bkg_vals, ergo\n",
    "binweights = signal_vals / bkg_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh dear, we get divide by zero! We will need to be careful about our binning.\n",
    "\n",
    "These are all coming from the very long tail we have in the histogram, and the empty bins at the beginning of the histogram.\n",
    "\n",
    "We can deal with this by lumping them all into an overflow bin and calculating a common weigh.\n",
    "\n",
    "Or, because we know it is just a very small effect in the tail, we can set the nan values to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binweights = np.nan_to_num(binweights,nan=1.0,posinf=1.0,neginf=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate a weight per event by looking up which bin they are in with a simple loop (there are better ways!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train = np.ones(len(x_train))\n",
    "for i in range(len(binweights)-1):\n",
    "    w_train[(x_train[:,0] >= ptbins[i]) & (x_train[:,0] < ptbins[i+1]) & (y_train == 0)] *= binweights[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross check that our weights make sense!\n",
    "print(np.unique(w_train[y_train==1]))\n",
    "print(np.unique(w_train[y_train==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the plot and get the values per bin\n",
    "#we are using weights to normalise the histograms to sum to unity in case we want to use the class weights in training\n",
    "x_train_sig = x_train[y_train==1]\n",
    "x_train_bkg = x_train[y_train==0]\n",
    "bkg_vals,ptbins,_= plt.hist(x_train_bkg[:,0], weights=w_train[y_train==0]*np.ones(len(x_train_bkg))/len(x_train_bkg), bins=np.arange(0,500e3,10e3),histtype='step',linestyle='-',linewidth=2,label='c-jets')\n",
    "signal_vals,ptbins,_=plt.hist(x_train_sig[:,0], weights=w_train[y_train==1]*np.ones(len(x_train_sig))/len(x_train_sig), bins=np.arange(0,500e3,10e3),histtype='step',linestyle='--',linewidth=2,label='b-jets')\n",
    "plt.xlabel('$p_T$ [MeV]')\n",
    "plt.ylabel('Normalised Entries')\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the distributions perfectly match for this binning!\n",
    "\n",
    "If you change the binning you will see some small discrepancies appear but this is much better than before.\n",
    "\n",
    "Now you can retrain the classifier and see what happens to the performance - do you expect it to drop or increase?\n",
    "\n",
    "You should now also look at the ROC curves in bins of $p_T$ (use the slice operator to separate your validation set based on this and recalculate the ROC curve each time.\n",
    "\n",
    "You can now also do the same for $\\eta$, and in principle both simultaneously!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint\n",
    "# Look at ROC curves in different bins of pT with\n",
    "# bins = np.arange(25e3,150e3,25e3)\n",
    "# for lower,upper in zip(bins[:-1],bins[1:]):\n",
    "#     x_val_t[(x_val[:,0] >= lower) & (x_val[:,0] < upper)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark\n",
    "\n",
    "One other problem with datasets is sometimes you have variables that aren't always defined.\n",
    "\n",
    "The data you have used so far has had these removed but there are several ways to handle them:\n",
    "\n",
    "* Don't use variables which can have nan values\n",
    "* Remove any event with nan values\n",
    "  * Assign all events with nan values to a class or pretend they don't exist\n",
    "* Set all nan values to a default value\n",
    "  * Use the mean value\n",
    "  * Motivate it from the physics you are looking at\n",
    "  * You may want to indicate to the network that you have done this with an extra variable which is 1 or 0 depending on whether you did this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
